{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Download any necessary datasets & dependencies, only need to do this once\n",
      "#import sys\n",
      "#!{sys.executable} -m pip install spacy\n",
      "#!{sys.executable} -m spacy download en_core_web_lg\n",
      "#!{sys.executable} -m pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.4.0/en_ner_bc5cdr_md-0.4.0.tar.gz\n",
      "#!{sys.executable} -m pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.4.0/en_ner_bionlp13cg_md-0.4.0.tar.gz\n",
      "#!{sys.executable} -m pip install numpy\n",
      "#!{sys.executable} -m pip install pandas\n",
      "#!{sys.executable} -m pip install requests\n",
      "#!{sys.executable} -m pip install matplotlib\n",
      "\n",
      "#Installing dependencies for classify_abs.py\n",
      "#!{sys.executable} -m pip install tensorflow\n",
      "#!{sys.executable} -m pip install nltk\n",
      "#import nltk\n",
      "#nltk.download('stopwords')\n",
      "#nltk.download('punkt')\n",
      "\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import classify_abs\n",
      "import requests\n",
      "import xml.etree.ElementTree as ET\n",
      "import spacy\n",
      "import time\n",
      "import datetime\n",
      "from collections import OrderedDict\n",
      "import matplotlib.pyplot as plt; plt.rcdefaults()"
     ],
     "language": "python",
     "metadata": {
      "scrolled": true
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "2021-07-06 18:50:14.134354: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
        "2021-07-06 18:50:14.134379: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Load data and classify it as epidemiological\n",
      "df = pd.read_csv('all_dz_abstract_set20.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.tail()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div>\n",
        "<style scoped>\n",
        "    .dataframe tbody tr th:only-of-type {\n",
        "        vertical-align: middle;\n",
        "    }\n",
        "\n",
        "    .dataframe tbody tr th {\n",
        "        vertical-align: top;\n",
        "    }\n",
        "\n",
        "    .dataframe thead th {\n",
        "        text-align: right;\n",
        "    }\n",
        "</style>\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>disease</th>\n",
        "      <th>pmid</th>\n",
        "      <th>abstract</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>98547</th>\n",
        "      <td>Sphingosine phosphate lyase insufficiency synd...</td>\n",
        "      <td>34131653</td>\n",
        "      <td>Systemic sclerosis (SSc) is a connective tissu...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>98548</th>\n",
        "      <td>Sphingosine phosphate lyase insufficiency synd...</td>\n",
        "      <td>34155851</td>\n",
        "      <td>&lt;h4&gt;Background&lt;/h4&gt;Surgical interventions in p...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>98549</th>\n",
        "      <td>Sphingosine phosphate lyase insufficiency synd...</td>\n",
        "      <td>34163540</td>\n",
        "      <td>&lt;h4&gt;Background&lt;/h4&gt;Systemic sclerosis (SSc) al...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>98550</th>\n",
        "      <td>Sphingosine phosphate lyase insufficiency synd...</td>\n",
        "      <td>34071779</td>\n",
        "      <td>&lt;b&gt;Objective:&lt;/b&gt; This nationwide study aimed ...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>98551</th>\n",
        "      <td>Sphingosine phosphate lyase insufficiency synd...</td>\n",
        "      <td>33548375</td>\n",
        "      <td>Digital ulcers (DU) are one of the most common...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "                                                 disease      pmid  \\\n",
        "98547  Sphingosine phosphate lyase insufficiency synd...  34131653   \n",
        "98548  Sphingosine phosphate lyase insufficiency synd...  34155851   \n",
        "98549  Sphingosine phosphate lyase insufficiency synd...  34163540   \n",
        "98550  Sphingosine phosphate lyase insufficiency synd...  34071779   \n",
        "98551  Sphingosine phosphate lyase insufficiency synd...  33548375   \n",
        "\n",
        "                                                abstract  \n",
        "98547  Systemic sclerosis (SSc) is a connective tissu...  \n",
        "98548  <h4>Background</h4>Surgical interventions in p...  \n",
        "98549  <h4>Background</h4>Systemic sclerosis (SSc) al...  \n",
        "98550  <b>Objective:</b> This nationwide study aimed ...  \n",
        "98551  Digital ulcers (DU) are one of the most common...  "
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Load spacy models for epi predictions\n",
      "nlp = spacy.load('en_core_web_lg')\n",
      "nlpSci = spacy.load(\"en_ner_bc5cdr_md\")\n",
      "nlpSci2 = spacy.load('en_ner_bionlp13cg_md')\n",
      "\n",
      "def epiPredictions(abstract, nlp, nlpSci, nlpSci2):\n",
      "    # predict on each abstract\n",
      "    prob, isEpi = classify_abs.getAbstractPredictions(abstract, nlp, nlpSci, nlpSci2, 'my_model_orphanet_final')\n",
      "    return prob, isEpi "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "epiprob = []\n",
      "epibool = []\n",
      "for row in df.iterrows():\n",
      "    type(row[1][2])\n",
      "    prob, boolean = epiPredictions(row[1][2], nlp, nlpSci, nlpSci2)\n",
      "    epiprob.append(prob)\n",
      "    epibool.append(boolean)"
     ],
     "language": "python",
     "metadata": {
      "scrolled": false
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "2021-07-06 18:50:32.286347: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
        "2021-07-06 18:50:32.286374: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
        "2021-07-06 18:50:32.286391: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (pubmed.ncats.io): /proc/driver/nvidia/version does not exist\n",
        "2021-07-06 18:50:32.286570: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
        "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "2021-07-06 18:50:39.675604: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
        "2021-07-06 18:50:39.697044: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2499995000 Hz\n"
       ]
      },
      {
       "ename": "NameError",
       "evalue": "name 'pmid' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m/tmp/ipykernel_27718/3378399849.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboolean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepiPredictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlpSci\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlpSci2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mepiprob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mepibool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboolean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/tmp/ipykernel_27718/2140984682.py\u001b[0m in \u001b[0;36mepiPredictions\u001b[0;34m(abstract, nlp, nlpSci, nlpSci2)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mepiPredictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabstract\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlpSci\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlpSci2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# predict on each abstract\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misEpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify_abs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetAbstractPredictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabstract\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlpSci\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlpSci2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'my_model_orphanet_final'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misEpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m~/classify_abs.py\u001b[0m in \u001b[0;36mgetAbstractPredictions\u001b[0;34m(abstract, nlp, nlpSci, nlpSci2, model)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabstract\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mabstract\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_abstract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpmid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;31m# load the tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'pmid' is not defined"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.insert(3,'epi_prob',epiprob)\n",
      "df.insert(4,'is_epi',epibool)\n",
      "df"
     ],
     "language": "python",
     "metadata": {
      "scrolled": true
     },
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "positive_sentence_set = df[df.epi_prob > 0.5].sort_values('epi_prob', ascending=False,ignore_index=True)\n",
      "positive_sentence_set"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "positive_sentence_set.to_csv('positive_abstract_set_epi.csv',index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.to_csv('whole_abstract_set_epi.csv',index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Start here if you already have the data classified"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#df = pd.read_csv('whole_abstract_set.csv')\n",
      "#df.tail()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create a dictionary of {disease name, number of epidemiological studies}\n",
      "dz_num = {}\n",
      "for row in df.iterrows():\n",
      "    if row[1][4]: #is_epi bool returned\n",
      "        if row[1][0] in dz_num.keys(): #Check if disease name is in dictionary\n",
      "            dz_num[row[1][0]]+=1\n",
      "        else:\n",
      "            dz_num[row[1][0]] = 1\n",
      "    elif row[1][0] not in dz_num.keys():\n",
      "            dz_num[row[1][0]] = 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot the figure\n",
      "objects = tuple(dz_num)\n",
      "performance = list(dz_num.values())\n",
      "\n",
      "fig = plt.figure()\n",
      "plt.ylabel('# of Diseases')\n",
      "plt.xlabel('# of Articles')\n",
      "plt.hist(performance)\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig.savefig('AllDiseaseEpi_Hist.png', dpi=400, bbox_inches='tight')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "zero, one, two, three, fourplus =0,0,0,0,0\n",
      "for k, v in dz_num.items():\n",
      "        if v>=4:\n",
      "            fourplus+=1\n",
      "        elif v==3:\n",
      "            three+=1\n",
      "        elif v==2:\n",
      "            two+=1\n",
      "        elif v==1:\n",
      "            one+=1\n",
      "        elif v==0:\n",
      "            zero+=1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(zero)\n",
      "print(one)\n",
      "print(two)\n",
      "print(three)\n",
      "print(fourplus)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}
