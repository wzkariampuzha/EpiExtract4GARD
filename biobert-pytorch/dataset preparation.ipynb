{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "602623f5",
   "metadata": {},
   "source": [
    "First need to see the form of the datasets that are prepared. There are four types:\n",
    "- devel.tsv\n",
    "- test.tsv\n",
    "- train.tsv\n",
    "- train_dev.tsv\n",
    "Will only be training on the NCBI Disease, 2010 i2b2/VA, BC5DR disease sets + my own records and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2529b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2684d488",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#See what the .tsv file looks like, can remove later\n",
    "#train_dev = \"./datasets/NER/NCBI-disease/train_dev.tsv\"\n",
    "#train = \"./datasets/NER/BC5CDR-disease/train.tsv\" \n",
    "test = \"./datasets/NER/BC5CDR-disease/test.tsv\"\n",
    "#train_dev = \"./datasets/NER/BC5CDR-disease/train_dev.tsv\"\n",
    "#devel = \"./datasets/NER/BC5CDR-disease/devel.tsv\"\n",
    "\n",
    "#Used this to find out if they used 80:20 split for training/validation - they did not\n",
    "#train_df = pd.read_csv(train, sep='\\t',engine='python',error_bad_lines=False)\n",
    "test_df = pd.read_csv(test, sep='\\t', names= [\"Word\",\"Label\"])\n",
    "#train_dev_df = pd.read_csv(train_dev, sep='\\t',engine='python',error_bad_lines=False)\n",
    "#devel_df = pd.read_csv(devel, sep='\\t')\n",
    "#print(len(train_df.index), len(test_df.index), len(train_dev_df.index), len(devel_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5b59dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Torsade</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>de</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pointes</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ventricular</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tachycardia</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124671</th>\n",
       "      <td>monitored</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124672</th>\n",
       "      <td>for</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124673</th>\n",
       "      <td>gingival</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124674</th>\n",
       "      <td>hyperplasia</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124675</th>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124676 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Word Label\n",
       "0           Torsade     B\n",
       "1                de     I\n",
       "2           pointes     I\n",
       "3       ventricular     B\n",
       "4       tachycardia     I\n",
       "...             ...   ...\n",
       "124671    monitored     O\n",
       "124672          for     O\n",
       "124673     gingival     B\n",
       "124674  hyperplasia     I\n",
       "124675            .     O\n",
       "\n",
       "[124676 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "823cb143",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset conllpp (/work/wzkariampuzha/.cache/huggingface/datasets/conllpp/conllpp/1.0.0/04f15f257dff3fe0fb36e049b73d51ecdf382698682f5e590b7fb13898206ba2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "coNLL = load_dataset(\"conllpp\")\n",
    "coNLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9a748ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0',\n",
       " 'tokens': ['EU',\n",
       "  'rejects',\n",
       "  'German',\n",
       "  'call',\n",
       "  'to',\n",
       "  'boycott',\n",
       "  'British',\n",
       "  'lamb',\n",
       "  '.'],\n",
       " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
       " 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
       " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coNLL[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f259e671",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('BRUSSELS', 'B'),\n",
       " ('1996-08-22', 'O'),\n",
       " ('Germany', 'B'),\n",
       " (\"'s\", 'O'),\n",
       " ('representative', 'O'),\n",
       " ('to', 'O'),\n",
       " ('the', 'O'),\n",
       " ('European', 'O'),\n",
       " ('Union', 'O'),\n",
       " (\"'s\", 'O'),\n",
       " ('veterinary', 'O'),\n",
       " ('committee', 'O'),\n",
       " ('Werner', 'O'),\n",
       " ('Zwingmann', 'O'),\n",
       " ('said', 'O'),\n",
       " ('on', 'O'),\n",
       " ('Wednesday', 'O'),\n",
       " ('consumers', 'O'),\n",
       " ('should', 'O'),\n",
       " ('buy', 'O'),\n",
       " ('sheepmeat', 'O'),\n",
       " ('from', 'O'),\n",
       " ('countries', 'O'),\n",
       " ('other', 'O'),\n",
       " ('than', 'O'),\n",
       " ('Britain', 'B'),\n",
       " ('until', 'O'),\n",
       " ('the', 'O'),\n",
       " ('scientific', 'O'),\n",
       " ('advice', 'O'),\n",
       " ('was', 'O'),\n",
       " ('clearer', 'O'),\n",
       " ('.', 'O'),\n",
       " ('Fischler', 'O'),\n",
       " ('proposed', 'O'),\n",
       " ('EU-wide', 'O'),\n",
       " ('measures', 'O'),\n",
       " ('after', 'O'),\n",
       " ('reports', 'O'),\n",
       " ('from', 'O'),\n",
       " ('Britain', 'B'),\n",
       " ('and', 'O'),\n",
       " ('France', 'B'),\n",
       " ('that', 'O'),\n",
       " ('under', 'O'),\n",
       " ('laboratory', 'O'),\n",
       " ('conditions', 'O'),\n",
       " ('sheep', 'O'),\n",
       " ('could', 'O'),\n",
       " ('contract', 'O'),\n",
       " ('Bovine', 'O'),\n",
       " ('Spongiform', 'O'),\n",
       " ('Encephalopathy', 'O'),\n",
       " ('(', 'O'),\n",
       " ('BSE', 'O')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NER_tag '5' is B-LOC, '6' is I-LOC\n",
    "loc_data = []\n",
    "for sentence in coNLL[\"train\"]:\n",
    "    #Only add sentences that actually have location tags (i.e. meaningfully annotated sentences)\n",
    "    if (5 in sentence['ner_tags'] or 6 in sentence['ner_tags']):\n",
    "        i = 0\n",
    "        for tag in sentence['ner_tags']:\n",
    "            label = 'O'\n",
    "            if tag ==5:\n",
    "                label = 'B'\n",
    "            if tag == 6:\n",
    "                label = 'I'\n",
    "            entry = (sentence['tokens'][i], label) #Adding this as a tuple\n",
    "            loc_data.append(entry)\n",
    "            i+=1\n",
    "loc_data[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6d4c669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def save_labels(loc_data, label_file):\n",
    "    with open(label_file, 'w', encoding='utf8', newline='') as tsv_file:\n",
    "        tsv_writer = csv.writer(tsv_file, delimiter='\\t', lineterminator='\\n')\n",
    "        #tsv_writer.writerow([\"Word\", \"Count\"])\n",
    "        for word, label in loc_data:\n",
    "            tsv_writer.writerow([word, label])\n",
    "#From https://stackoverflow.com/questions/29895602/how-to-save-output-from-python-like-tsv\n",
    "#WWHre word_count is a list of tuples like this:\n",
    "#[('the', 222594), ('to', 61479), ('in', 52540), ('of', 48064) ... ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a427de67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_file = \"./datasets/NER/labels.tsv\"\n",
    "save_labels(loc_data, label_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "164c26ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84361</th>\n",
       "      <td>74</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84362</th>\n",
       "      <td>77</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84363</th>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84364</th>\n",
       "      <td>LONDON</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84365</th>\n",
       "      <td>1996-08-30</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Word Label\n",
       "84361          74     O\n",
       "84362          77     O\n",
       "84363           .     O\n",
       "84364      LONDON     B\n",
       "84365  1996-08-30     O"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(label_file, sep='\\t', names= [\"Word\",\"Label\"]) \n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dbdf5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split = 0.8\n",
    "half = int(len(df.index)/2)\n",
    "butterknife = int(train_test_split*len(df.index))\n",
    "\n",
    "df_1 = df[:half]\n",
    "df_2 = df[half:]\n",
    "\n",
    "train_df = df_1[:butterknife]\n",
    "test_df = df_1[butterknife:]\n",
    "train_dev_df = df_2[:butterknife]\n",
    "devel_df = df_2[butterknife:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "760e37da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save files\n",
    "train = \"./datasets/NER/Location/train.tsv\" \n",
    "test = \"./datasets/NER/Location/test.tsv\"\n",
    "train_dev = \"./datasets/NER/Location/train_dev.tsv\"\n",
    "devel = \"./datasets/NER/Location/devel.tsv\"\n",
    "\n",
    "train_df.to_csv(train,sep='\\t',header=False, index = False)\n",
    "test_df.to_csv(test,sep='\\t',header=False, index = False)\n",
    "train_dev_df.to_csv(train_dev,sep='\\t',header=False, index = False)\n",
    "devel_df.to_csv(devel,sep='\\t',header=False, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95872aec",
   "metadata": {},
   "source": [
    "This is using the train_test_split module, did not use it because BERT trains contextually so randomizing the words are most likely worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "371ccd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#x, y = train_test_split(df, train_size = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d512853",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e11d01d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bce77fb1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df.groupby('Label').size().reset_index(name='Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7e6eac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = df.drop('Label', axis=1)\n",
    "#print(X.to_dict('records')[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c1a341f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.feature_extraction import DictVectorizer\\n\\nX = df.drop('Label', axis=1)\\nv = DictVectorizer(sparse=False)\\nX = v.fit_transform(X.to_dict('records'))\\ny = df.Label.values\\nclasses = np.unique(y)\\nclasses = classes.tolist()\\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state=0)\\nX_train.shape, y_train.shape\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "X = df.drop('Label', axis=1)\n",
    "v = DictVectorizer(sparse=False)\n",
    "X = v.fit_transform(X.to_dict('records'))\n",
    "y = df.Label.values\n",
    "classes = np.unique(y)\n",
    "classes = classes.tolist()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state=0)\n",
    "X_train.shape, y_train.shape\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d186b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d00de536",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.linear_model import Perceptron\n",
    "#per = Perceptron(verbose=10, n_jobs=-1, max_iter=5)\n",
    "#per.partial_fit(X_train, y_train, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a6b858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_classes = classes.copy()\n",
    "#new_classes.pop()\n",
    "#new_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5b1d81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import classification_report\n",
    "#print(classification_report(y_pred=per.predict(X_test), y_true=y_test, labels=new_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cd28b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
